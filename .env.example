# Discord Bot Configuration
DISCORD_TOKEN=your_discord_bot_token_here

# ============================================================================
# LLM Configuration
# ============================================================================
# Mode: 'internal' (run model locally) or 'external' (use API endpoint)
LLM_MODE=external

# ============================================================================
# OPTION 1: Internal Mode (GPU inference in bot process)
# Requires: GPU machine, 8GB+ VRAM, fine-tuned model on disk
# ============================================================================
# LLM_MODE=internal
# MODEL_PATH=/path/to/your/lora/adapter/or/merged/model

# ============================================================================
# OPTION 2: External Mode - Modal.com (Recommended for 1GB RAM Oracle)
# Free: $30/month credit (~100k-1M tokens)
# Setup: See MODAL_DEPLOYMENT_GUIDE.md
# ============================================================================
LLM_MODE=external
LLM_ENDPOINT_URL=https://your-workspace--soyebot-llm.modal.run

# ============================================================================
# OPTION 3: External Mode - RunPod.io
# Free: $5-500 starting credit (cheapest long-term)
# Setup: Deploy vLLM on RunPod, expose with ngrok
# ============================================================================
# LLM_MODE=external
# LLM_ENDPOINT_URL=https://your-ngrok-url.ngrok.io/v1

# ============================================================================
# OPTION 4: External Mode - Local Development (LM Studio, Ollama, vLLM)
# Free: Completely free (runs on your machine)
# ============================================================================
# LLM_MODE=external
# LLM_ENDPOINT_URL=http://localhost:1234/v1

# ============================================================================
# OPTION 5: External Mode - Google Colab (Free but 24h limit)
# Free: Completely free GPU
# Note: Session restarts every 24 hours
# ============================================================================
# LLM_MODE=external
# LLM_ENDPOINT_URL=https://your-colab-ngrok-url.ngrok.io/v1
