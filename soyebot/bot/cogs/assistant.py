"""Assistant Cog for SoyeBot."""

import logging
import time
import asyncio
from typing import Optional

import discord
from discord.ext import commands

from bot.chat_handler import ChatReply, create_chat_reply, resolve_session_for_message
from bot.session import SessionManager
from bot.buffer import MessageBuffer
from config import AppConfig
from metrics import get_metrics
from services.llm_service import LLMService
from utils import GENERIC_ERROR_MESSAGE, extract_message_content

logger = logging.getLogger(__name__)

class AssistantCog(commands.Cog):
    """@mentionì„ í†µí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ê¸°ëŠ¥ì„ ì²˜ë¦¬í•˜ëŠ” Cog"""

    def __init__(
        self,
        bot: commands.Bot,
        config: AppConfig,
        llm_service: LLMService,
        session_manager: SessionManager,
    ):
        self.bot = bot
        self.config = config
        self.llm_service = llm_service
        self.session_manager = session_manager
        self.message_buffer = MessageBuffer(delay=config.message_buffer_delay)

    def _should_ignore_message(self, message: discord.Message) -> bool:
        """Return True when the bot should not process the message."""

        if message.author.bot:
            return True
        # If this channel is handled by AutoChannelCog, let it handle the response
        # to avoid duplicate replies (one plain, one reply).
        if message.channel.id in self.config.auto_reply_channel_ids:
            return True
        if not self.bot.user or not self.bot.user.mentioned_in(message):
            return True
        return message.mention_everyone

    async def _send_llm_reply(self, message: discord.Message, reply: ChatReply) -> None:
        if not reply.text:
            logger.debug("LLM returned no text response for the mention.")
            return

        reply_message = await message.reply(reply.text, mention_author=False)
        if reply_message:
            self.session_manager.link_message_to_session(str(reply_message.id), reply.session_key)

    @commands.Cog.listener()
    async def on_message(self, message: discord.Message):
        if self._should_ignore_message(message):
            return

        await self.message_buffer.add_message(message.channel.id, message, self._process_batch)

    async def _process_batch(self, messages: list[discord.Message]):
        if not messages:
            return

        # Use the first message for context/reply target, but could be improved
        primary_message = messages[0]
        start_time = time.perf_counter()
        metrics = get_metrics()

        try:
            # Combine contents
            combined_content = []
            for msg in messages:
                content = extract_message_content(msg)
                if content:
                    if len(messages) > 1 and msg.author.name:
                         combined_content.append(f"{msg.author.name}: {content}")
                    else:
                         combined_content.append(content)

            full_text = "\n".join(combined_content)

            if not full_text:
                await primary_message.reply("âŒ ë©”ì‹œì§€ ë‚´ìš©ì´ ì—†ëŠ”ë°ìš”.", mention_author=False)
                return

            logger.info("Processing batch of %d messages from %s: %s", len(messages), primary_message.author.name, full_text[:100])

            async with primary_message.channel.typing():
                resolution = await resolve_session_for_message(
                    primary_message,
                    full_text,
                    session_manager=self.session_manager,
                )

                if not resolution:
                    await primary_message.reply("âŒ ë©”ì‹œì§€ ë‚´ìš©ì´ ì—†ëŠ”ë°ìš”.", mention_author=False)
                    return

                reply = await create_chat_reply(
                    primary_message,
                    resolution=resolution,
                    llm_service=self.llm_service,
                    session_manager=self.session_manager,
                )

                if reply:
                    # We reply to the last message in the batch so the user sees it at the bottom
                    last_message = messages[-1]
                    await self._send_llm_reply(last_message, reply)

            duration_ms = (time.perf_counter() - start_time) * 1000
            metrics.record_latency('message_processing', duration_ms)
            metrics.increment_counter('messages_processed')

        except Exception as e:
            logger.error("ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: %s", e, exc_info=True)
            await primary_message.reply(GENERIC_ERROR_MESSAGE, mention_author=False)
            duration_ms = (time.perf_counter() - start_time) * 1000
            metrics.record_latency('message_processing', duration_ms)

    @commands.command(name='ì´ˆê¸°í™”', aliases=['reset'])
    async def reset_session(self, ctx: commands.Context):
        """í˜„ì¬ ì±„ë„ì˜ ëŒ€í™” ì„¸ì…˜ì„ ìˆ˜ë™ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""

        try:
            self.session_manager.reset_session_by_channel(ctx.channel.id)
            await ctx.message.add_reaction("âœ…")
            await asyncio.sleep(5)
            await ctx.message.remove_reaction("âœ…", ctx.bot.user)
        except Exception as exc:
            logger.error("ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: %s", exc, exc_info=True)
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)

    @commands.command(name='temp')
    @commands.has_permissions(manage_guild=True)
    async def set_temperature(self, ctx: commands.Context, value: Optional[float] = None):
        """Set the temperature parameter for the LLM (0.0 - 2.0)."""
        if value is None:
            current_temp = getattr(self.config, 'temperature', 1.0)
            await ctx.reply(f"ğŸŒ¡ï¸ í˜„ì¬ Temperature: {current_temp}", mention_author=False)
            return

        if not (0.0 <= value <= 2.0):
            await ctx.reply("âŒ TemperatureëŠ” 0.0ì—ì„œ 2.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.", mention_author=False)
            return

        try:
            self.llm_service.update_parameters(temperature=value)
            await ctx.message.add_reaction("âœ…")
            await asyncio.sleep(5)
            await ctx.message.remove_reaction("âœ…", ctx.bot.user)
        except Exception as e:
            logger.error("Temperature ì„¤ì • ì‹¤íŒ¨: %s", e, exc_info=True)
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)

    @commands.command(name='topp')
    @commands.has_permissions(manage_guild=True)
    async def set_top_p(self, ctx: commands.Context, value: Optional[float] = None):
        """Set the top_p parameter for the LLM (0.0 - 1.0)."""
        if value is None:
            current_top_p = getattr(self.config, 'top_p', 1.0)
            await ctx.reply(f"ğŸ“Š í˜„ì¬ Top-p: {current_top_p}", mention_author=False)
            return

        if not (0.0 <= value <= 1.0):
            await ctx.reply("âŒ Top-pëŠ” 0.0ì—ì„œ 1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.", mention_author=False)
            return

        try:
            self.llm_service.update_parameters(top_p=value)
            await ctx.message.add_reaction("âœ…")
            await asyncio.sleep(5)
            await ctx.message.remove_reaction("âœ…", ctx.bot.user)
        except Exception as e:
            logger.error("Top-p ì„¤ì • ì‹¤íŒ¨: %s", e, exc_info=True)
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)
