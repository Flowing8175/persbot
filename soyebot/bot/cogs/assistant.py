"""Assistant Cog for SoyeBot."""

import logging
import time
import asyncio
import re
from typing import Optional

import discord
from discord.ext import commands

from bot.chat_handler import ChatReply, create_chat_reply, resolve_session_for_message, send_split_response
from bot.session import SessionManager, ResolvedSession
from bot.buffer import MessageBuffer
from config import AppConfig
from services.llm_service import LLMService
from services.base import ChatMessage
from services.prompt_service import PromptService
from utils import GENERIC_ERROR_MESSAGE, extract_message_content

logger = logging.getLogger(__name__)

class AssistantCog(commands.Cog):
    """@mentionì„ í†µí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ê¸°ëŠ¥ì„ ì²˜ë¦¬í•˜ëŠ” Cog"""

    def __init__(
        self,
        bot: commands.Bot,
        config: AppConfig,
        llm_service: LLMService,
        session_manager: SessionManager,
        prompt_service: PromptService,
    ):
        self.bot = bot
        self.config = config
        self.llm_service = llm_service
        self.session_manager = session_manager
        self.prompt_service = prompt_service
        self.sending_tasks: dict[int, asyncio.Task] = {}
        
        # Track active processing tasks (LLM generation) to allow debouncing/merging
        self.processing_tasks: dict[int, asyncio.Task] = {}
        self.active_batches: dict[int, list[discord.Message]] = {}
        
        # Use config for default delay (now 0.1)
        self.message_buffer = MessageBuffer(delay=config.message_buffer_delay)

    def _should_ignore_message(self, message: discord.Message) -> bool:
        """Return True when the bot should not process the message."""

        if message.author.bot:
            return True
        # If this channel is handled by AutoChannelCog, let it handle the response
        # to avoid duplicate replies (one plain, one reply).
        if message.channel.id in self.config.auto_reply_channel_ids:
            return True
        if not self.bot.user or not self.bot.user.mentioned_in(message):
            return True
        return message.mention_everyone

    async def _send_llm_reply(self, message: discord.Message, reply: ChatReply) -> None:
        if not reply.text:
            logger.debug("LLM returned no text response for the mention.")
            return

        # If Break-Cut Mode is OFF, send normally
        if not self.config.break_cut_mode:
            reply_message = await message.reply(reply.text, mention_author=False)
            if reply_message:
                self.session_manager.link_message_to_session(str(reply_message.id), reply.session_key)
            return

        # If Break-Cut Mode is ON, use shared helper
        channel_id = message.channel.id
        if channel_id in self.sending_tasks and not self.sending_tasks[channel_id].done():
            self.sending_tasks[channel_id].cancel()

        task = asyncio.create_task(
            send_split_response(message.channel, reply, self.session_manager)
        )
        self.sending_tasks[channel_id] = task

        def _cleanup(t):
            if self.sending_tasks.get(channel_id) == t:
                self.sending_tasks.pop(channel_id, None)
        
        task.add_done_callback(_cleanup)

    @commands.Cog.listener()
    async def on_message(self, message: discord.Message):
        if self._should_ignore_message(message):
            return

        # Interrupt current sending if any (Break-Cut Mode)
        if self.config.break_cut_mode and message.channel.id in self.sending_tasks:
            task = self.sending_tasks[message.channel.id]
            if not task.done():
                logger.info(f"New message from {message.author} interrupted sending in channel {message.channel.id}")
                task.cancel()

        # Interrupt current processing (Processing/Debounce Mode)
        messages_to_prepend = []
        if message.channel.id in self.processing_tasks:
            task = self.processing_tasks[message.channel.id]
            if not task.done():
                logger.info(f"New message from {message.author} interrupted processing in channel {message.channel.id}. Merging messages.")
                messages_to_prepend = self.active_batches.get(message.channel.id, [])
                task.cancel()

        await self.message_buffer.add_message(message.channel.id, message, self._process_batch)
        
        if messages_to_prepend:
             # Ensure the list exists before prepending
             if message.channel.id in self.message_buffer.buffers:
                 self.message_buffer.buffers[message.channel.id][0:0] = messages_to_prepend

    @commands.Cog.listener()
    async def on_typing(self, channel: discord.abc.Messageable, user: discord.abc.User, when: float):
        """
        Listener for typing events.
        Extends the processing delay if a user is typing in a channel where we have pending messages.
        """
        if user.bot:
            return

        # We need the channel ID. 'channel' can be TextChannel, DMChannel, etc.
        if hasattr(channel, 'id'):
            # If Break-Cut Mode is OFF, use the old "Extend Wait" logic.
            # If ON, we do NOT extend wait (user request: "delete user input wait").
            if not self.config.break_cut_mode:
                self.message_buffer.handle_typing(channel.id, self._process_batch)

    async def _process_batch(self, messages: list[discord.Message]):
        if not messages:
            return

        # Use the first message for context/reply target, but could be improved
        primary_message = messages[0]
        channel_id = primary_message.channel.id
        
        # Register this task as the active processing task for the channel
        self.active_batches[channel_id] = messages
        self.processing_tasks[channel_id] = asyncio.current_task()

        try:
            # 1. Fetch recent context (10 messages before the primary message)
            context_messages = [
                msg async for msg in primary_message.channel.history(limit=10, before=primary_message)
            ]
            context_messages.reverse()  # Chronological order

            context_text = ""
            if context_messages:
                context_lines = []
                for msg in context_messages:
                    c_content = extract_message_content(msg)
                    if c_content:
                        context_lines.append(f"{msg.author.id}: {c_content}")

                if context_lines:
                    context_text = "=== ì´ì „ ëŒ€í™” ë¬¸ë§¥ (ì°¸ê³ ìš©) ===\n" + "\n".join(context_lines) + "\n=== í˜„ì¬ ë©”ì‹œì§€ ===\n"

            # 2. Combine current batch contents
            combined_content = []
            for msg in messages:
                content = extract_message_content(msg)
                if content:
                    if len(messages) > 1 and msg.author.id:
                         combined_content.append(f"{msg.author.id}: {content}")
                    else:
                         combined_content.append(content)

            current_text = "\n".join(combined_content)

            if not current_text:
                return

            # Prepend context to the full text
            full_text = context_text + current_text

            logger.info("Processing batch of %d messages from %s: %s", len(messages), primary_message.author.name, full_text[:100])

            async with primary_message.channel.typing():
                resolution = await resolve_session_for_message(
                    primary_message,
                    full_text,
                    session_manager=self.session_manager,
                )

                if not resolution:
                    return

                reply = await create_chat_reply(
                    primary_message,
                    resolution=resolution,
                    llm_service=self.llm_service,
                    session_manager=self.session_manager,
                )

                if reply:
                    # We reply to the last message in the batch so the user sees it at the bottom
                    last_message = messages[-1]
                    await self._send_llm_reply(last_message, reply)

        except asyncio.CancelledError:
            logger.info("Batch processing cancelled for channel %s.", primary_message.channel.name)
            raise

        except Exception as e:
            logger.error("ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: %s", e, exc_info=True)
            await primary_message.reply(GENERIC_ERROR_MESSAGE, mention_author=False)
        
        finally:
            # Cleanup only if we are the current task
            if self.processing_tasks.get(channel_id) == asyncio.current_task():
                self.processing_tasks.pop(channel_id, None)
                self.active_batches.pop(channel_id, None)

    @commands.command(name='help', aliases=['ë„ì›€ë§', 'ëª…ë ¹ì–´', 'h'])
    async def help_command(self, ctx: commands.Context):
        """ë´‡ì˜ ëª¨ë“  ëª…ë ¹ì–´ì™€ ì‚¬ìš©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."""
        embed = discord.Embed(
            title="ğŸ¤– ëª…ë ¹ì–´ ê°€ì´ë“œ",
            description=f"ì ‘ë‘ì‚¬: `{self.config.command_prefix}` ë˜ëŠ” `@mention`ì„ ì‚¬ìš©í•˜ì—¬ ëª…ë ¹ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            color=discord.Color.blue()
        )

        # 1. ëŒ€í™” ì œì–´
        embed.add_field(
            name="ğŸ’¬ ëŒ€í™” ì œì–´",
            value=(
                "`!retry` (`!ë‹¤ì‹œ`): ë§ˆì§€ë§‰ ë‹µë³€ì„ ì§€ìš°ê³  ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.\n"
                "`!reset` (`!ì´ˆê¸°í™”`): í˜„ì¬ ì±„ë„ì˜ ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n"
                "`!undo [N]` (`!@`): ë§ˆì§€ë§‰ Nê°œì˜ ëŒ€í™” ìŒì„ ì‚­ì œí•©ë‹ˆë‹¤. (ìë™ì‘ë‹µ ì±„ë„ ì „ìš©)\n"
                "`!abort` (`!ì¤‘ë‹¨`): ì§„í–‰ ì¤‘ì¸ ì „ì†¡ì´ë‚˜ AI ì²˜ë¦¬ë¥¼ ì¦‰ì‹œ ë©ˆì¶¥ë‹ˆë‹¤."
            ),
            inline=False
        )

        # 2. ìš”ì•½ ë° ë¶„ì„
        embed.add_field(
            name="ğŸ“ ìš”ì•½ ë° ë¶„ì„",
            value=(
                "`!ìš”ì•½`: ìµœê·¼ 30ë¶„ ëŒ€í™”ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.\n"
                "`!ìš”ì•½ <ì‹œê°„>`: ì§€ì • ì‹œê°„(ì˜ˆ: `20ë¶„`, `1ì‹œê°„`) ë™ì•ˆì˜ ëŒ€í™”ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.\n"
                "`!ìš”ì•½ <ID> ì´í›„`: íŠ¹ì • ë©”ì‹œì§€ ì´í›„ì˜ ëŒ€í™”ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."
            ),
            inline=False
        )

        # 3. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ (Persona)
        embed.add_field(
            name="ğŸ­ í”„ë¡¬í”„íŠ¸ (í˜ë¥´ì†Œë‚˜) ê´€ë¦¬",
            value=(
                "`!prompt`: í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ UIë¥¼ ì—½ë‹ˆë‹¤. (ìƒì„±, ëª©ë¡, ì„ íƒ, ì‚­ì œ ë“±)\n"
            ),
            inline=False
        )

        # 4. ì„¤ì • ë° íŒŒë¼ë¯¸í„°
        embed.add_field(
            name="âš™ï¸ ì„¤ì • ë° íŒŒë¼ë¯¸í„°",
            value=(
                "`!temp <0.0~2.0>`: AIì˜ ì°½ì˜ì„±(Temperature)ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n"
                "`!ìƒê° <ìˆ«ì|auto|off>`: Gemini Thinking Budgetë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n"
                "`!ëŠì–´ì¹˜ê¸° [on|off]`: ì‹¤ì‹œê°„ ë©”ì‹œì§€ ëŠì–´ ì „ì†¡ ëª¨ë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
            ),
            inline=False
        )

        embed.set_footer(text="SoyeBot | Advanced Agentic Coding Assistant")
        await ctx.reply(embed=embed, mention_author=False)

    @commands.command(name='retry', aliases=['ì¬ìƒì„±', 'ë‹¤ì‹œ'])
    async def retry_command(self, ctx: commands.Context):
        """Re-generate the last assistant response."""
        channel_id = ctx.channel.id
        session_key = f"channel:{channel_id}"

        # 1. Cancel any active tasks first
        if channel_id in self.processing_tasks:
            task = self.processing_tasks[channel_id]
            if not task.done():
                logger.info("Retry command interrupted active processing in channel #%s", ctx.channel.name)
                task.cancel()
        
        if channel_id in self.sending_tasks:
            task = self.sending_tasks[channel_id]
            if not task.done():
                logger.info("Retry command interrupted active sending in channel #%s", ctx.channel.name)
                task.cancel()

        # 2. Undo the last exchange (assistant + user message)
        removed_messages: list[ChatMessage] = self.session_manager.undo_last_exchanges(session_key, 1)

        if not removed_messages:
            await ctx.reply("âŒ ë˜ëŒë¦´ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.", mention_author=False)
            return

        # Identify the user message content and the previous assistant message ID
        user_role = self.llm_service.get_user_role_name()
        assistant_role = self.llm_service.get_assistant_role_name()

        user_content = ""
        # Process removed messages to find content and IDs
        # Removed messages are chronological. Expect [User, Assistant] usually.
        for msg in removed_messages:
            if msg.role == user_role:
                user_content = msg.content
            elif msg.role == assistant_role:
                if hasattr(msg, 'message_ids') and msg.message_ids:
                    # Collect all message IDs for deletion
                    for mid in msg.message_ids:
                        try:
                            old_msg = await ctx.channel.fetch_message(int(mid))
                            await old_msg.delete()
                        except (discord.NotFound, discord.Forbidden, discord.HTTPException):
                            pass

        if not user_content:
            await ctx.send("âŒ ì¬ì‹œë„í•  ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # Re-generate response
        async with ctx.channel.typing():
            resolution = ResolvedSession(session_key, user_content)

            # Create a reply using the original context author (ctx.author) which is acceptable for retry
            reply = await create_chat_reply(
                ctx.message,
                resolution=resolution,
                llm_service=self.llm_service,
                session_manager=self.session_manager,
            )

            if reply and reply.text:
                # We always send a new reply for retry now, as old ones were deleted
                await self._send_llm_reply(ctx.message, reply)
            else:
                 await ctx.send(GENERIC_ERROR_MESSAGE)

        # Attempt to delete the retry command message itself for cleanliness
        try:
            await ctx.message.delete()
        except (discord.Forbidden, discord.HTTPException):
            pass

    @commands.command(name='abort', aliases=['ì¤‘ë‹¨', 'ë©ˆì¶°'])
    @commands.has_permissions(manage_guild=True)
    async def abort_command(self, ctx: commands.Context):
        """ì§„í–‰ ì¤‘ì¸ ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ë° ì²˜ë¦¬ë¥¼ ê°•ì œë¡œ ì¤‘ë‹¨í•©ë‹ˆë‹¤."""
        channel_id = ctx.channel.id
        aborted = False

        # 1. Interrupt tasks in AssistantCog
        # Cancel sending
        if channel_id in self.sending_tasks:
            task = self.sending_tasks[channel_id]
            if not task.done():
                task.cancel()
                aborted = True

        # Cancel processing
        if channel_id in self.processing_tasks:
            task = self.processing_tasks[channel_id]
            if not task.done():
                task.cancel()
                aborted = True

        # 2. Try to interrupt tasks in AutoChannelCog
        auto_cog = self.bot.get_cog("AutoChannelCog")
        if auto_cog:
            # Cancel sending tasks
            if channel_id in auto_cog.sending_tasks:
                task = auto_cog.sending_tasks[channel_id]
                if not task.done():
                    task.cancel()
                    aborted = True
            
            # Cancel processing tasks
            if hasattr(auto_cog, 'processing_tasks') and channel_id in auto_cog.processing_tasks:
                task = auto_cog.processing_tasks[channel_id]
                if not task.done():
                    task.cancel()
                    aborted = True
        
        if aborted:
            await ctx.message.add_reaction("ğŸ›‘")
            logger.info("User %s requested abort in channel %s", ctx.author.name, channel_id)
        else:
            await ctx.message.add_reaction("â“")

    @commands.command(name='ì´ˆê¸°í™”', aliases=['reset'])
    async def reset_session(self, ctx: commands.Context):
        """í˜„ì¬ ì±„ë„ì˜ ëŒ€í™” ì„¸ì…˜ì„ ìˆ˜ë™ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""

        try:
            self.session_manager.reset_session_by_channel(ctx.channel.id)
            await ctx.message.add_reaction("âœ…")
        except Exception as exc:
            logger.error("ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: %s", exc, exc_info=True)
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)

    @commands.command(name='temp')
    @commands.has_permissions(manage_guild=True)
    async def set_temperature(self, ctx: commands.Context, value: Optional[float] = None):
        """Set the temperature parameter for the LLM (0.0 - 2.0)."""
        if value is None:
            current_temp = getattr(self.config, 'temperature', 1.0)
            await ctx.reply(f"ğŸŒ¡ï¸ í˜„ì¬ Temperature: {current_temp}", mention_author=False)
            return

        if not (0.0 <= value <= 2.0):
            await ctx.reply("âŒ TemperatureëŠ” 0.0ì—ì„œ 2.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.", mention_author=False)
            return

        try:
            self.llm_service.update_parameters(temperature=value)
            await ctx.message.add_reaction("âœ…")
        except Exception as e:
            logger.error("Temperature ì„¤ì • ì‹¤íŒ¨: %s", e, exc_info=True)
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)

    @commands.command(name='topp')
    @commands.has_permissions(manage_guild=True)
    async def set_top_p(self, ctx: commands.Context, value: Optional[float] = None):
        """Set the top_p parameter for the LLM (0.0 - 1.0)."""
        if value is None:
            current_top_p = getattr(self.config, 'top_p', 1.0)
            await ctx.reply(f"ğŸ“Š í˜„ì¬ Top-p: {current_top_p}", mention_author=False)
            return

        if not (0.0 <= value <= 1.0):
            await ctx.reply("âŒ Top-pëŠ” 0.0ì—ì„œ 1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.", mention_author=False)
            return

        try:
            self.llm_service.update_parameters(top_p=value)
            await ctx.message.add_reaction("âœ…")
        except Exception as e:
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)
    
    @commands.command(name='ëŠì–´ì¹˜ê¸°')
    async def toggle_break_cut(self, ctx: commands.Context, mode: Optional[str] = None):
        """ëŠì–´ì¹˜ê¸° ëª¨ë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (!ëŠì–´ì¹˜ê¸° [on|off], ì¸ì ì—†ì´ ì‚¬ìš© ì‹œ í† ê¸€)"""
        if mode is None:
            # Toggle
            self.config.break_cut_mode = not self.config.break_cut_mode
        else:
            cleaned = mode.lower().strip()
            if cleaned == 'on':
                self.config.break_cut_mode = True
            elif cleaned == 'off':
                self.config.break_cut_mode = False
            else:
                await ctx.reply("ì‚¬ìš©ë²•: !ëŠì–´ì¹˜ê¸° [on|off] (ìƒëµ ì‹œ í† ê¸€)")
                return

        status = "ON" if self.config.break_cut_mode else "OFF"
        
        # Adjust buffer behavior based on mode? 
        # Actually user requested "remove wait" globally. 
        # But we did that in __init__ (delay=0.1).
        # We only gated handle_typing in on_typing.
        
        await ctx.reply(f"âœ‚ï¸ ëŠì–´ì¹˜ê¸° ëª¨ë“œê°€ **{status}** ìƒíƒœë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")

    @commands.command(name='ìƒê°', aliases=['think'])
    @commands.has_permissions(manage_guild=True)
    async def set_thinking_budget(self, ctx: commands.Context, value: Optional[str] = None):
        """Gemini Thinking Budgetë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (!ìƒê° [ìˆ«ì|auto|off])"""
        if value is None:
            current = getattr(self.config, 'thinking_budget', None)
            if current is None:
                display = 'OFF'
            elif current == -1:
                display = 'AUTO'
            else:
                display = str(current)
            status = f"í˜„ì¬ Thinking Budget: **{display}**"
            await ctx.reply(f"ğŸ§  {status}", mention_author=False)
            return

        cleaned = value.lower().strip()
        target_value: Optional[int] = None

        if cleaned == 'off':
            target_value = None
        elif cleaned == 'auto':
            target_value = -1 # Special value for dynamic budget
        else:
            try:
                target_value = int(cleaned)
                if not (512 <= target_value <= 32768):
                    await ctx.reply("âŒ Thinking Budgetì€ 512ì—ì„œ 32768 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.", mention_author=False)
                    return
            except ValueError:
                await ctx.reply("âŒ ì˜¬ë°”ë¥¸ ìˆ«ì(512~32768), 'auto', ë˜ëŠ” 'off'ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.", mention_author=False)
                return

        try:
            self.llm_service.update_parameters(thinking_budget=target_value)
            await ctx.message.add_reaction("âœ…")

        except Exception as e:
            logger.error("Thinking Budget ì„¤ì • ì‹¤íŒ¨: %s", e, exc_info=True)
            await ctx.reply(GENERIC_ERROR_MESSAGE, mention_author=False)

    async def cog_command_error(self, ctx: commands.Context, error: Exception):
        """Cog ë‚´ ëª…ë ¹ì–´ ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
        if isinstance(error, commands.MissingPermissions):
            await ctx.reply(f"âŒ ì´ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. (í•„ìš” ê¶Œí•œ: {', '.join(error.missing_permissions)})", mention_author=False)
        elif isinstance(error, commands.BadArgument):
            await ctx.reply("âŒ ì˜ëª»ëœ ì¸ìê°€ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤. ëª…ë ¹ì–´ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.", mention_author=False)
        elif isinstance(error, commands.CommandOnCooldown):
            await ctx.reply(f"â³ ì¿¨ë‹¤ìš´ ì¤‘ì…ë‹ˆë‹¤. {error.retry_after:.1f}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", mention_author=False)
        else:
            logger.error(f"Command error in {ctx.command}: {error}", exc_info=True)
            # ê¸°ë³¸ ì—ëŸ¬ ë©”ì‹œì§€ëŠ” ì´ë¯¸ globally ì²˜ë¦¬ë  ìˆ˜ë„ ìˆì§€ë§Œ, cog ë ˆë²¨ì—ì„œ í•œë²ˆ ë” í™•ì¸
            if not ctx.command.has_error_handler():
                await ctx.reply(f"âŒ ëª…ë ¹ì–´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(error)}", mention_author=False)
